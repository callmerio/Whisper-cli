#!/usr/bin/env python3
"""
è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨ (Voice Activity Detector)
ç”¨äºå®æ—¶æ£€æµ‹ç”¨æˆ·è¯­éŸ³æ´»åŠ¨ï¼Œæ”¯æŒæ™ºèƒ½åˆ†æ®µå’Œå¯é…ç½®çš„é™éŸ³æ£€æµ‹
"""

import time
import threading
import queue
from typing import Optional, Callable, List
from dataclasses import dataclass
from enum import Enum
import numpy as np

import config


class VoiceActivityState(Enum):
    """è¯­éŸ³æ´»åŠ¨çŠ¶æ€"""
    SILENT = "é™éŸ³"
    SPEAKING = "è¯´è¯ä¸­"
    PAUSED = "æš‚åœ"


@dataclass
class VoiceSegment:
    """è¯­éŸ³æ®µæ•°æ®ç»“æ„"""
    start_time: float  # å¼€å§‹æ—¶é—´
    end_time: float    # ç»“æŸæ—¶é—´
    audio_data: np.ndarray  # éŸ³é¢‘æ•°æ®
    duration: float    # æ—¶é•¿ï¼ˆç§’ï¼‰
    segment_id: str    # æ®µè½ID
    
    @property
    def duration_ms(self) -> int:
        """æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰"""
        return int(self.duration * 1000)


class VoiceActivityDetector:
    """è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–VAD"""
        # é…ç½®å‚æ•°
        self.volume_threshold = config.VAD_VOLUME_THRESHOLD  # éŸ³é‡é˜ˆå€¼
        self.silence_duration = config.VAD_SILENCE_DURATION  # é™éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
        self.min_segment_duration = config.VAD_MIN_SEGMENT_DURATION  # æœ€å°æ®µè½æ—¶é•¿
        self.sample_rate = config.SAMPLE_RATE
        self.analysis_window = config.VAD_ANALYSIS_WINDOW  # åˆ†æçª—å£ï¼ˆç§’ï¼‰
        
        # çŠ¶æ€ç®¡ç†
        self.current_state = VoiceActivityState.SILENT
        self.last_voice_time = None
        self.current_segment_start = None
        self.segment_audio_buffer = []
        self.segment_counter = 0
        
        # çº¿ç¨‹æ§åˆ¶
        self.running = False
        self.audio_queue = queue.Queue()
        self.processing_thread = None
        self.lock = threading.Lock()
        
        # å›è°ƒå‡½æ•°
        self.on_segment_complete: Optional[Callable[[VoiceSegment], None]] = None
        self.on_voice_start: Optional[Callable[[], None]] = None
        self.on_voice_stop: Optional[Callable[[], None]] = None
        self.on_state_change: Optional[Callable[[VoiceActivityState], None]] = None
        
        print(f"ğŸ¯ è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   éŸ³é‡é˜ˆå€¼: {self.volume_threshold}")
        print(f"   é™éŸ³æ£€æµ‹: {self.silence_duration}ç§’")
        print(f"   æœ€å°æ®µè½: {self.min_segment_duration}ç§’")
    
    def set_callbacks(self, 
                     on_segment_complete: Optional[Callable[[VoiceSegment], None]] = None,
                     on_voice_start: Optional[Callable[[], None]] = None,
                     on_voice_stop: Optional[Callable[[], None]] = None,
                     on_state_change: Optional[Callable[[VoiceActivityState], None]] = None):
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self.on_segment_complete = on_segment_complete
        self.on_voice_start = on_voice_start
        self.on_voice_stop = on_voice_stop
        self.on_state_change = on_state_change
    
    def update_config(self, silence_duration: Optional[float] = None,
                     volume_threshold: Optional[float] = None,
                     min_segment_duration: Optional[float] = None):
        """æ›´æ–°é…ç½®å‚æ•°"""
        with self.lock:
            if silence_duration is not None:
                self.silence_duration = silence_duration
                print(f"ğŸ”§ æ›´æ–°é™éŸ³æ£€æµ‹æ—¶é•¿: {silence_duration}ç§’")
            
            if volume_threshold is not None:
                self.volume_threshold = volume_threshold
                print(f"ğŸ”§ æ›´æ–°éŸ³é‡é˜ˆå€¼: {volume_threshold}")
            
            if min_segment_duration is not None:
                self.min_segment_duration = min_segment_duration
                print(f"ğŸ”§ æ›´æ–°æœ€å°æ®µè½æ—¶é•¿: {min_segment_duration}ç§’")
    
    def start(self) -> bool:
        """å¯åŠ¨VAD"""
        if self.running:
            return True
        
        self.running = True
        self.processing_thread = threading.Thread(target=self._processing_worker, daemon=True)
        self.processing_thread.start()
        
        print("ğŸš€ è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨å·²å¯åŠ¨")
        return True
    
    def stop(self):
        """åœæ­¢VAD"""
        if not self.running:
            return
        
        self.running = False
        
        # å¤„ç†æœ€åä¸€ä¸ªæ®µè½ï¼ˆå¦‚æœæœ‰ï¼‰
        self._finalize_current_segment()
        
        # ç­‰å¾…å¤„ç†çº¿ç¨‹ç»“æŸ
        if self.processing_thread and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=2.0)
        
        print("â¹ï¸ è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨å·²åœæ­¢")
    
    def feed_audio(self, audio_data: np.ndarray, timestamp: Optional[float] = None):
        """è¾“å…¥éŸ³é¢‘æ•°æ®è¿›è¡Œåˆ†æ"""
        if not self.running:
            return
        
        if timestamp is None:
            timestamp = time.time()
        
        # å°†éŸ³é¢‘æ•°æ®æ”¾å…¥é˜Ÿåˆ—
        try:
            self.audio_queue.put((audio_data, timestamp), timeout=0.1)
        except queue.Full:
            # é˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒæ—§æ•°æ®
            try:
                self.audio_queue.get_nowait()
                self.audio_queue.put((audio_data, timestamp), timeout=0.1)
            except (queue.Empty, queue.Full):
                pass
    
    def _processing_worker(self):
        """éŸ³é¢‘å¤„ç†å·¥ä½œçº¿ç¨‹"""
        print("ğŸ”„ VADå¤„ç†çº¿ç¨‹å·²å¯åŠ¨")
        
        while self.running:
            try:
                # è·å–éŸ³é¢‘æ•°æ®
                audio_data, timestamp = self.audio_queue.get(timeout=0.5)
                
                # åˆ†æéŸ³é¢‘
                self._analyze_audio_chunk(audio_data, timestamp)
                
                # æ¯æ¬¡å¤„ç†å®ŒéŸ³é¢‘åéƒ½æ£€æŸ¥é™éŸ³è¶…æ—¶ï¼Œç¡®ä¿åŠæ—¶æ£€æµ‹åˆ°é™éŸ³
                self._check_silence_timeout()
                
            except queue.Empty:
                # è¶…æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†é™éŸ³
                self._check_silence_timeout()
                continue
            except Exception as e:
                if config.DEBUG_MODE:
                    print(f"âš ï¸ VADå¤„ç†å¼‚å¸¸: {e}")
        
        print("ğŸ”„ VADå¤„ç†çº¿ç¨‹å·²ç»“æŸ")
    
    def _analyze_audio_chunk(self, audio_data: np.ndarray, timestamp: float):
        """åˆ†æéŸ³é¢‘æ•°æ®å—"""
        # è®¡ç®—éŸ³é¢‘èƒ½é‡/éŸ³é‡
        if len(audio_data) == 0:
            return
        
        # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯æ­£ç¡®çš„æ ¼å¼
        if audio_data.dtype == np.float32:
            # å¦‚æœå·²ç»æ˜¯float32ï¼Œå‡è®¾èŒƒå›´æ˜¯-1åˆ°1
            audio_float = audio_data
        else:
            # è½¬æ¢ä¸ºfloat32ï¼Œå‡è®¾æ˜¯16ä½æ•´æ•°
            audio_float = audio_data.astype(np.float32) / 32768.0
        
        # è®¡ç®—RMSéŸ³é‡
        rms_volume = np.sqrt(np.mean(audio_float ** 2))
        
        # åˆ¤æ–­æ˜¯å¦æœ‰è¯­éŸ³æ´»åŠ¨
        has_voice = rms_volume > self.volume_threshold
        
        with self.lock:
            previous_state = self.current_state
            
            if has_voice:
                # æ£€æµ‹åˆ°è¯­éŸ³
                self.last_voice_time = timestamp
                
                if self.current_state == VoiceActivityState.SILENT:
                    # ä»é™éŸ³è½¬ä¸ºè¯´è¯
                    self._start_new_segment(timestamp)
                    self.current_state = VoiceActivityState.SPEAKING
                    
                    if self.on_voice_start:
                        try:
                            self.on_voice_start(timestamp)
                        except Exception as e:
                            if config.DEBUG_MODE:
                                print(f"âš ï¸ è¯­éŸ³å¼€å§‹å›è°ƒå¼‚å¸¸: {e}")
                
                elif self.current_state == VoiceActivityState.PAUSED:
                    # ä»æš‚åœæ¢å¤è¯´è¯
                    self.current_state = VoiceActivityState.SPEAKING
                
                # å°†éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°å½“å‰æ®µè½
                self.segment_audio_buffer.append(audio_data)
            
            else:
                # æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³
                if self.current_state == VoiceActivityState.SPEAKING:
                    # ä»è¯´è¯è½¬ä¸ºæš‚åœ
                    self.current_state = VoiceActivityState.PAUSED
                
                # å³ä½¿æ˜¯é™éŸ³ï¼Œä¹Ÿè¦å°†éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°å½“å‰æ®µè½ï¼ˆä¿æŒéŸ³é¢‘è¿ç»­æ€§ï¼‰
                if self.current_state in [VoiceActivityState.SPEAKING, VoiceActivityState.PAUSED]:
                    self.segment_audio_buffer.append(audio_data)
            
            # æ£€æŸ¥çŠ¶æ€å˜åŒ–
            if previous_state != self.current_state:
                if self.on_state_change:
                    try:
                        self.on_state_change(previous_state, self.current_state)
                    except Exception as e:
                        if config.DEBUG_MODE:
                            print(f"âš ï¸ çŠ¶æ€å˜åŒ–å›è°ƒå¼‚å¸¸: {e}")
    
    def _check_silence_timeout(self):
        """æ£€æŸ¥é™éŸ³è¶…æ—¶"""
        if not self.last_voice_time:
            return
        
        current_time = time.time()
        silence_time = current_time - self.last_voice_time
        
        with self.lock:
            if (self.current_state in [VoiceActivityState.SPEAKING, VoiceActivityState.PAUSED] and
                silence_time >= self.silence_duration):
                
                # é™éŸ³è¶…æ—¶ï¼Œå®Œæˆå½“å‰æ®µè½
                self._finalize_current_segment()
                self.current_state = VoiceActivityState.SILENT
                
                if self.on_voice_stop:
                    try:
                        self.on_voice_stop(current_time)
                    except Exception as e:
                        if config.DEBUG_MODE:
                            print(f"âš ï¸ è¯­éŸ³åœæ­¢å›è°ƒå¼‚å¸¸: {e}")
    
    def _start_new_segment(self, timestamp: float):
        """å¼€å§‹æ–°çš„è¯­éŸ³æ®µè½"""
        self.current_segment_start = timestamp
        self.segment_audio_buffer = []
        self.segment_counter += 1
    
    def _finalize_current_segment(self):
        """å®Œæˆå½“å‰è¯­éŸ³æ®µè½"""
        if not self.current_segment_start or not self.segment_audio_buffer:
            return
        
        current_time = time.time()
        duration = current_time - self.current_segment_start
        
        # æ£€æŸ¥æ®µè½é•¿åº¦
        if duration < self.min_segment_duration:
            self._reset_segment()
            return
        
        # åˆå¹¶éŸ³é¢‘æ•°æ®
        if self.segment_audio_buffer:
            combined_audio = np.concatenate(self.segment_audio_buffer)
        else:
            combined_audio = np.array([], dtype=np.int16)
        
        # åˆ›å»ºè¯­éŸ³æ®µè½å¯¹è±¡
        segment = VoiceSegment(
            start_time=self.current_segment_start,
            end_time=current_time,
            audio_data=combined_audio,
            duration=duration,
            segment_id=f"segment_{self.segment_counter}_{int(self.current_segment_start * 1000)}"
        )
        
        print(f"âœ… å®Œæˆæ®µè½: {segment.segment_id} ({duration:.1f}s, {len(combined_audio)} é‡‡æ ·ç‚¹)")
        
        # è°ƒç”¨å›è°ƒå‡½æ•°
        if self.on_segment_complete:
            try:
                self.on_segment_complete(segment)
            except Exception as e:
                print(f"âŒ æ®µè½å®Œæˆå›è°ƒå¼‚å¸¸: {e}")
                if config.DEBUG_MODE:
                    import traceback
                    traceback.print_exc()
        
        # é‡ç½®æ®µè½çŠ¶æ€
        self._reset_segment()
    
    def _reset_segment(self):
        """é‡ç½®æ®µè½çŠ¶æ€"""
        self.current_segment_start = None
        self.segment_audio_buffer = []
    
    def get_current_state(self) -> VoiceActivityState:
        """è·å–å½“å‰çŠ¶æ€"""
        return self.current_state
    
    def get_current_silence_duration(self) -> float:
        """è·å–å½“å‰é™éŸ³æ—¶é•¿"""
        if not self.last_voice_time:
            return 0.0
        
        return time.time() - self.last_voice_time
    
    def force_segment_complete(self):
        """å¼ºåˆ¶å®Œæˆå½“å‰æ®µè½"""
        with self.lock:
            if self.current_state in [VoiceActivityState.SPEAKING, VoiceActivityState.PAUSED]:
                self._finalize_current_segment()
                self.current_state = VoiceActivityState.SILENT
                
                if self.on_voice_stop:
                    try:
                        current_time = time.time()
                        self.on_voice_stop(current_time)
                    except Exception as e:
                        if config.DEBUG_MODE:
                            print(f"âš ï¸ å¼ºåˆ¶åœæ­¢å›è°ƒå¼‚å¸¸: {e}")
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "current_state": self.current_state.value,
            "segment_count": self.segment_counter,
            "current_silence_duration": self.get_current_silence_duration(),
            "config": {
                "volume_threshold": self.volume_threshold,
                "silence_duration": self.silence_duration,
                "min_segment_duration": self.min_segment_duration
            }
        }


def test_vad():
    """æµ‹è¯•VADåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨...")
    
    def on_segment(segment: VoiceSegment):
        print(f"ğŸ“ æ®µè½å®Œæˆ: {segment.segment_id}, æ—¶é•¿: {segment.duration:.1f}s")
    
    def on_voice_start():
        print("ğŸ¤ å¼€å§‹è¯´è¯")
    
    def on_voice_stop():
        print("â¹ï¸ åœæ­¢è¯´è¯")
    
    def on_state_change(state: VoiceActivityState):
        print(f"ğŸ”„ çŠ¶æ€å˜åŒ–: {state.value}")
    
    vad = VoiceActivityDetector()
    vad.set_callbacks(
        on_segment_complete=on_segment,
        on_voice_start=on_voice_start,
        on_voice_stop=on_voice_stop,
        on_state_change=on_state_change
    )
    
    vad.start()
    
    # æ¨¡æ‹ŸéŸ³é¢‘è¾“å…¥
    try:
        for i in range(100):
            # ç”Ÿæˆæ¨¡æ‹ŸéŸ³é¢‘ï¼ˆæœ‰/æ— è¯­éŸ³ï¼‰
            if 20 <= i <= 40 or 60 <= i <= 80:
                # æ¨¡æ‹Ÿæœ‰è¯­éŸ³çš„éŸ³é¢‘
                audio = np.random.normal(0, 0.1, 1600).astype(np.int16)  # 0.1ç§’çš„éŸ³é¢‘
            else:
                # æ¨¡æ‹Ÿé™éŸ³
                audio = np.random.normal(0, 0.005, 1600).astype(np.int16)
            
            vad.feed_audio(audio)
            time.sleep(0.1)
    
    except KeyboardInterrupt:
        pass
    
    finally:
        vad.stop()
        print("âœ… VADæµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_vad()